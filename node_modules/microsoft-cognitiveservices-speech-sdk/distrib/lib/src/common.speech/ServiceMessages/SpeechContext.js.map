{"version":3,"sources":["src/common.speech/ServiceMessages/SpeechContext.ts"],"names":[],"mappings":";AAAA,EAAE;AACF,gDAAgD;AAChD,wGAAwG;AACxG,EAAE","file":"SpeechContext.js","sourcesContent":["//\r\n// Copyright (c) Microsoft. All rights reserved.\r\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\r\n//\r\n\r\nimport { InvocationSource } from \"./InvocationSource\";\r\nimport { KeywordDetection } from \"./KeywordDetection/KeywordDetection\";\r\nimport { PhraseDetectionContext } from \"./PhraseDetection/PhraseDetectionContext\";\r\nimport { Intent } from \"./Intent/Intent\";\r\nimport { Dgi } from \"./Dgi/Dgi\";\r\nimport { PhraseOutput } from \"./PhraseOutput/PhraseOutput\";\r\nimport { LanguageIdContext } from \"./LanguageId/LanguageIdContext\";\r\nimport { TranslationContext } from \"./Translation/TranslationContext\";\r\nimport { SynthesisContext } from \"./Synthesis/SynthesisContext\";\r\nimport { PronunciationScoreContext } from \"./PronunciationScore/PronunciationScoreContext\";\r\nimport { CtsAudioContinuation } from \"./MultichannelAudio/CtsAudioContinuation\";\r\nimport { Dictation } from \"./Scenario/Dictation\";\r\n\r\n/**\r\n * The speech context type.\r\n * Note: Deserialization won't fail if certain context attribute is null since they are all optional.\r\n * This interface will eventually support all speech context use cases, in practice, depending on the use case\r\n * only a portion of the following context attributes will be present during deserialization.\r\n */\r\nexport interface SpeechContext {\r\n    /**\r\n     * CTS Continuation token for audio stream\r\n     */\r\n    continuation?: CtsAudioContinuation;\r\n\r\n    /**\r\n     * The invocation source.\r\n     */\r\n    invocationSource?: InvocationSource;\r\n\r\n    /**\r\n     * The keyword detection.\r\n     */\r\n    keywordDetection?: KeywordDetection[];\r\n\r\n    /**\r\n     * The dictation.\r\n     */\r\n    dictation?: Dictation;\r\n\r\n    /**\r\n     * The phrase detection.\r\n     */\r\n    phraseDetection?: PhraseDetectionContext;\r\n\r\n    /**\r\n     * The intent context\r\n     */\r\n    intent?: Intent;\r\n\r\n    /**\r\n     * Dynamic Grammar Information\r\n     */\r\n    dgi?: Dgi;\r\n\r\n    /**\r\n     * Phrase Output\r\n     */\r\n    phraseOutput?: PhraseOutput;\r\n\r\n    /**\r\n     * The language identifier.\r\n     */\r\n    languageId?: LanguageIdContext;\r\n\r\n    /**\r\n     * The translation.\r\n     */\r\n    translation?: TranslationContext;\r\n\r\n    /**\r\n     * The synthesis.\r\n     */\r\n    synthesis?: SynthesisContext;\r\n\r\n    /**\r\n     * The pronunciaion score configuration.\r\n     */\r\n    pronunciationScore?: PronunciationScoreContext;\r\n\r\n    /**\r\n     * Allow adding ability to add custom context attributes.\r\n     * This is useful for adding custom context attributes that are not part of the Speech SDK.\r\n     */\r\n    [key: string]: any;\r\n}\r\n"]}